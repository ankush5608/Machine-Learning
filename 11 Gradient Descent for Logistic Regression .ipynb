{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d84528f2",
   "metadata": {},
   "source": [
    "# Gradient Descent for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5f2bd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math,copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b221b9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=np.array([[0.5, 1.5], [1,1], [1.5, 0.5], [3, 0.5], [2, 2], [1, 2.5]])\n",
    "y_train=np.array([0,0,0,1,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8ad240d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    sigm=1/(1+np.exp(-z))\n",
    "    return sigm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8792489",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost_logistic(x,y,w,b):\n",
    "    m=x.shape[0]\n",
    "    cost=0\n",
    "    for i in range(m):\n",
    "        f_wb=np.dot(w,x[i])+b\n",
    "        g_z=sigmoid(f_wb)\n",
    "        cost+=-y[i]*(np.log(g_z))-(1-y[i])*(np.log(1-g_z))\n",
    "    cost=cost/m\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f21fc6",
   "metadata": {},
   "source": [
    "## Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "967ad7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient_logistic(x,y,w,b):\n",
    "    m,n = x.shape\n",
    "    dj_dw = np.zeros((n,))\n",
    "    dj_db=0\n",
    "    for i in range(m):\n",
    "        f_wb = np.dot(w,x[i])+b\n",
    "        g_z = sigmoid(f_wb)\n",
    "        err = g_z -y[i]\n",
    "        for j in range(n):\n",
    "            dj_dw[j] = dj_dw[j] + err*x[i,j]\n",
    "        dj_db=dj_db + err\n",
    "    dj_dw=dj_dw/m\n",
    "    dj_db=dj_db/m\n",
    "    \n",
    "    return dj_dw,dj_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "18b30ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dj_db: 0.49861806546328574\n",
      "dj_dw: [0.49833339 0.49883943]\n"
     ]
    }
   ],
   "source": [
    "X_tmp = np.array([[0.5, 1.5], [1,1], [1.5, 0.5], [3, 0.5], [2, 2], [1, 2.5]])\n",
    "y_tmp = np.array([0, 0, 0, 1, 1, 1])\n",
    "w_tmp = np.array([2.,3.])\n",
    "b_tmp = 1.\n",
    "dj_dw_tmp, dj_db_tmp = compute_gradient_logistic(X_tmp, y_tmp, w_tmp, b_tmp)\n",
    "print(f\"dj_db: {dj_db_tmp}\" )\n",
    "print(f\"dj_dw: {dj_dw_tmp}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a23c1f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(x,y,w,b,num_iters,alpha):\n",
    "    j_history=[]\n",
    "    for i in range(num_iters):\n",
    "        dj_dw,dj_db=compute_gradient_logistic(x,y,w,b)\n",
    "        b=b-alpha*dj_db\n",
    "        w=w-alpha*dj_dw\n",
    "    \n",
    "        if i<100000:\n",
    "            j_history.append(compute_cost_logistic(x,y,w,b))\n",
    "            \n",
    "        if i%math.ceil(num_iters/10)==0:\n",
    "            print(f\"iteration:{i:4} and cost:{j_history[-1]}\")\n",
    "            \n",
    "    return w,b,j_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b7ec887f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:   0 and cost:0.684610468560574\n",
      "iteration:1000 and cost:0.1590977666870457\n",
      "iteration:2000 and cost:0.08460064176930078\n",
      "iteration:3000 and cost:0.05705327279402531\n",
      "iteration:4000 and cost:0.04290759421682\n",
      "iteration:5000 and cost:0.03433847729884557\n",
      "iteration:6000 and cost:0.02860379802212006\n",
      "iteration:7000 and cost:0.02450156960879306\n",
      "iteration:8000 and cost:0.02142370332569295\n",
      "iteration:9000 and cost:0.019030137124109114\n",
      "\n",
      "updated parameters: w:[5.28123029 5.07815608], b:-14.222409982019837\n"
     ]
    }
   ],
   "source": [
    "w_tmp  = np.zeros_like(x_train[0])\n",
    "b_tmp  = 0.\n",
    "alpha = 0.1\n",
    "iters = 10000\n",
    "\n",
    "w_out, b_out, j_hist = gradient_descent(x_train, y_train, w_tmp, b_tmp,iters,alpha) \n",
    "print(f\"\\nupdated parameters: w:{w_out}, b:{b_out}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58d21f7",
   "metadata": {},
   "source": [
    "Predicting output with the model trained values of w and b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d75cb8bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01862297 0.02057229 0.02272091 0.98463772 0.99849336 0.97711696]\n"
     ]
    }
   ],
   "source": [
    "m=x_train.shape[0]\n",
    "prediction=np.zeros(m)\n",
    "for i in range(m):\n",
    "    prediction[i]=sigmoid(np.dot(w_out,x_train[i])+b_out)\n",
    "    \n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd34c09",
   "metadata": {},
   "source": [
    "Thus we get the required output with this model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
