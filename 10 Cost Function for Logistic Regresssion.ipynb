{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "493b29e7",
   "metadata": {},
   "source": [
    "# Cost Function for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7939fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4ce232f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=np.array([[0.5, 1.5], [1,1], [1.5, 0.5], [3, 0.5], [2, 2], [1, 2.5]])\n",
    "y_train=np.array([0,0,0,1,1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2996bb8b",
   "metadata": {},
   "source": [
    "## Cost function\n",
    "\n",
    "In a previous lab, you developed the *logistic loss* function. Recall, loss is defined to apply to one example. Here you combine the losses to form the **cost**, which includes all the examples.\n",
    "\n",
    "\n",
    "Recall that for logistic regression, the cost function is of the form \n",
    "\n",
    "$$ J(\\mathbf{w},b) = \\frac{1}{m} \\sum_{i=0}^{m-1} \\left[ loss(f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}), y^{(i)}) \\right] \\$$\n",
    "\n",
    "where\n",
    "* $loss(f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}), y^{(i)})$ is the cost for a single data point, which is:\n",
    "\n",
    "    $$loss(f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}), y^{(i)}) = -y^{(i)} \\log\\left(f_{\\mathbf{w},b}\\left( \\mathbf{x}^{(i)} \\right) \\right) - \\left( 1 - y^{(i)}\\right) \\log \\left( 1 - f_{\\mathbf{w},b}\\left( \\mathbf{x}^{(i)} \\right) \\right) \\$$\n",
    "    \n",
    "*  where m is the number of training examples in the data set and:\n",
    "$$\n",
    "\\begin{align}\n",
    "  f_{\\mathbf{w},b}(\\mathbf{x^{(i)}}) &= g(z^{(i)}) \\\\\n",
    "  z^{(i)} &= \\mathbf{w} \\cdot \\mathbf{x}^{(i)}+ b \\\\\n",
    "  g(z^{(i)}) &= \\frac{1}{1+e^{-z^{(i)}}}\\ \n",
    "\\end{align}\n",
    "$$\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7f6f71",
   "metadata": {},
   "source": [
    "#### Code Description\n",
    "\n",
    "The algorithm for `compute_cost_logistic` loops over all the examples calculating the loss for each example and accumulating the total.\n",
    "\n",
    "Note that the variables X and y are not scalar values but matrices of shape ($m, n$) and ($ùëö$,) respectively, where  $ùëõ$ is the number of features and $ùëö$ is the number of training examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fa043e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    sigm=1/(1+np.exp(-z))\n",
    "    return sigm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a3cd522",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost_logistic(x,y,w,b):\n",
    "    m=x.shape[0]\n",
    "    cost=0\n",
    "    for i in range(m):\n",
    "        f_wb=np.dot(w,x[i])+b\n",
    "        g_z=sigmoid(f_wb)\n",
    "        cost+=-y[i]*(np.log(g_z))-(1-y[i])*(np.log(1-g_z))\n",
    "    cost_final=cost/m\n",
    "    return cost_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2507d675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36686678640551745\n"
     ]
    }
   ],
   "source": [
    "w_tmp = np.array([1,1])\n",
    "b_tmp = -3\n",
    "print(compute_cost_logistic(x_train, y_train, w_tmp, b_tmp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8112d0",
   "metadata": {},
   "source": [
    "Now if we try with other values of b and try computing for the cost we see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "552c884e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost for b = -3 :  0.36686678640551745\n",
      "Cost for b = -4 :  0.5036808636748461\n"
     ]
    }
   ],
   "source": [
    "w_array1 = np.array([1,1])\n",
    "b_1 = -3\n",
    "w_array2 = np.array([1,1])\n",
    "b_2 = -4\n",
    "\n",
    "print(\"Cost for b = -3 : \", compute_cost_logistic(x_train, y_train, w_array1, b_1))\n",
    "print(\"Cost for b = -4 : \", compute_cost_logistic(x_train, y_train, w_array2, b_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8f1390",
   "metadata": {},
   "source": [
    "We can see the cost function behaves as expected and the cost for `b = -4, w = np.array([1,1])` is indeed higher than the cost for `b = -3, w = np.array([1,1])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb0349f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
