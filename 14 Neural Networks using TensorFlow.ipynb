{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55f60106",
   "metadata": {},
   "source": [
    "# Simple Neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bffc6f1",
   "metadata": {},
   "source": [
    "Linear and Logistic Regression implementation using Tensorflow\n",
    "and Some simple Neural network creation using tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6db0ed1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense,Input\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.losses import MeanSquaredError,BinaryCrossentropy\n",
    "from tensorflow.keras.activations import sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fed19fa",
   "metadata": {},
   "source": [
    "## Neuron without activation - Regression/Linear Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4df0887",
   "metadata": {},
   "source": [
    "Building a Linear Regression model using neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187ae24b",
   "metadata": {},
   "source": [
    "We are building the same housing price prediction model of lab1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75619772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " x_train=[[1.]\n",
      " [2.]]\n",
      " y_train=[[300.]\n",
      " [500.]]\n"
     ]
    }
   ],
   "source": [
    "x_train = np.array([[1.0],[2.0]],dtype = np.float32)\n",
    "y_train = np.array([[300.0],[500.0]],dtype = np.float32)\n",
    "print(f\" x_train={x_train}\\n y_train={y_train}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2db9b93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_layer = tf.keras.layers.Dense(1,activation = 'linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e36be62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.layers.core.dense.Dense object at 0x0000020600357E50>\n"
     ]
    }
   ],
   "source": [
    "print(linear_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "602eb2a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_layer.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ba9652",
   "metadata": {},
   "source": [
    "if we try to get weights from the above model it will be empty because we have not provided with input layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5e9db6",
   "metadata": {},
   "source": [
    "There are no weights as the weights are not yet instantiated. Let's try the model on one example in `X_train`. This will trigger the instantiation of the weights. Note, the input to the layer must be 2-D, so we'll reshape it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86ffe55c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.53825676]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a1 = linear_layer(x_train[0].reshape(1,1))\n",
    "print(a1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38db1bb7",
   "metadata": {},
   "source": [
    "here we are applying one row as input to neural network to initalize weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249c8cd7",
   "metadata": {},
   "source": [
    "The result is a tensor (another name for an array) with a shape of (1,1) or one entry.   \n",
    "Now let's look at the weights and bias. These weights are randomly initialized to small numbers and the bias defaults to being initialized to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5382108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w=[[0.53825676]] and b=[0.]\n"
     ]
    }
   ],
   "source": [
    "w,b=linear_layer.get_weights()\n",
    "print(f\"w={w} and b={b}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7d4bd6",
   "metadata": {},
   "source": [
    "A linear regression model (1) with a single input feature will have a single weight and bias. This matches the dimensions of our `linear_layer` above.   \n",
    "\n",
    "The weights are initialized to random values so let's set them to some known values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "949a9912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[200.]], dtype=float32), array([100.], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "set_w = np.array([[200]])\n",
    "set_b = np.array([100])\n",
    "\n",
    "linear_layer.set_weights([set_w,set_b])\n",
    "print(linear_layer.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c8f81b",
   "metadata": {},
   "source": [
    "predicting the output house price for x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90f11e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[300.]], shape=(1, 1), dtype=float32)\n",
      "[300.]\n"
     ]
    }
   ],
   "source": [
    "a1 = linear_layer(x_train[0].reshape(1,1))\n",
    "print(a1)\n",
    "\n",
    "alin = np.dot(set_w,x_train[0])+set_b\n",
    "print(alin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa560fc",
   "metadata": {},
   "source": [
    "Predicting x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d70ea7a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction using tensorflow \n",
      "[[300.]\n",
      " [500.]]\n",
      "Prediction using numpy \n",
      "[[300.]\n",
      " [500.]]\n"
     ]
    }
   ],
   "source": [
    "prediction_tf = linear_layer(x_train)\n",
    "prediction_np = np.dot(x_train,set_w)+set_b\n",
    "print(f\"Prediction using tensorflow \\n{prediction_tf}\")\n",
    "print(f\"Prediction using numpy \\n{prediction_np}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f878dfe0",
   "metadata": {},
   "source": [
    "## Logistic Regression using the neurons and neural network Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10d1565",
   "metadata": {},
   "source": [
    "We are using the same example of Logistic Regression which we had used before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec71ed1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " x_train = \n",
      "[[0.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [4.]\n",
      " [5.]]\n",
      " y_train = \n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "x_train = np.array([0.,1,2,3,4,5],dtype=np.float32).reshape(-1,1)\n",
    "y_train = np.array([0,0,0,1,1,1],dtype=np.float32).reshape(-1,1)\n",
    "print(f\" x_train = \\n{x_train}\\n y_train = \\n{y_train}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af75904",
   "metadata": {},
   "source": [
    "### Logistic Neuron\n",
    "We can implement a 'logistic neuron' by adding a sigmoid activation.    \n",
    "This section will create a Tensorflow Model that contains our logistic layer to demonstrate an alternate method of creating models. Tensorflow is most often used to create multi-layer models. The [Sequential](https://keras.io/guides/sequential_model/) model is a convenient means of constructing these models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "352f2ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(\n",
    "[\n",
    "    tf.keras.layers.Dense(1,input_dim=1,activation='sigmoid',name='L1')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7250a083",
   "metadata": {},
   "source": [
    "Here we are building the model by passing input_dim=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519dd4e3",
   "metadata": {},
   "source": [
    "`model.summary()` shows the layers and number of parameters in the model. There is only one layer in this model and that layer has only one unit. The unit has two parameters, $w$ and $b$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1989253b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " L1 (Dense)                  (None, 1)                 2         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2c499d",
   "metadata": {},
   "source": [
    "here param represents the parameters w and b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98ea5356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w=[[-0.87320167]] and b=[0.]\n",
      "w.shape=(1, 1) and b.shape=(1,)\n"
     ]
    }
   ],
   "source": [
    "Logistic_layer = model.get_layer('L1')\n",
    "w,b = Logistic_layer.get_weights()\n",
    "print(f\"w={w} and b={b}\")\n",
    "print(f\"w.shape={w.shape} and b.shape={b.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8d3ee6",
   "metadata": {},
   "source": [
    "Similar to linear regression here the weights will be set to some value and b as 0, when given some input(i.e the weights which we get by initalizing is not the optimal weights which we require) if we dont initialize the model by passing input then it will give empty set of weights and bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ad5897",
   "metadata": {},
   "source": [
    "Let's set the weight and bias to some known values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6af12463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w=[[2.]] and b=[-4.5]\n"
     ]
    }
   ],
   "source": [
    "set_w = np.array([[2]])\n",
    "set_b = np.array([-4.5])\n",
    "Logistic_layer.set_weights([set_w,set_b]) \n",
    "w,b = Logistic_layer.get_weights()\n",
    "print(f\"w={w} and b={b}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce38dace",
   "metadata": {},
   "source": [
    "Lets predict using this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3678a463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 156ms/step\n",
      "[[0.01098694]]\n"
     ]
    }
   ],
   "source": [
    "a1 = model.predict(x_train[0].reshape(1,1))\n",
    "print(a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58ebd05f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01098694]\n"
     ]
    }
   ],
   "source": [
    "alog = (np.dot(set_w,x_train[0])+set_b)\n",
    "a1 = 1/(1+np.exp(-alog))\n",
    "print(a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ef57f416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 5ms/step\n",
      "[[0.01098694]\n",
      " [0.07585818]\n",
      " [0.37754068]\n",
      " [0.8175745 ]\n",
      " [0.97068775]\n",
      " [0.99592984]]\n",
      "\n",
      " [0. 0. 0. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "a1=model.predict(x_train)\n",
    "print(a1)\n",
    "\n",
    "num=x_train.shape[0]\n",
    "a_out=np.zeros(num)\n",
    "for i in range(num):\n",
    "    if a1[i]>=0.5:\n",
    "        a_out[i]=1\n",
    "    else:\n",
    "        a_out[i]=0\n",
    "print(\"\\n\",a_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76673d17",
   "metadata": {},
   "source": [
    "Thus we built the Linear and Logistic Regression models using Tensorflow neuron architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93e6b6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
