{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "665d5c41",
   "metadata": {},
   "source": [
    "# SoftMax Regression/ MultiClass Classification "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63abadad",
   "metadata": {},
   "source": [
    "When we have to classify between more than 2 objects then we use softmax regresssion. Consider an exmple where we classify 10 handwritten digits there we use softmax regression which gives the probability to every distinct handwritten digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f51afc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39270dc",
   "metadata": {},
   "source": [
    "# Creating Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "592dbe83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "centers = [[-5, 2], [-2, -2], [1, 2], [5, -2]]\n",
    "X_train, y_train = make_blobs(n_samples=2000, centers=centers, cluster_std=1.0,random_state=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6fdfc8",
   "metadata": {},
   "source": [
    "## Method with Numerical Roundoff errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d6c36f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "63/63 [==============================] - 0s 777us/step - loss: 1.3370\n",
      "Epoch 2/10\n",
      "63/63 [==============================] - 0s 676us/step - loss: 0.4996\n",
      "Epoch 3/10\n",
      "63/63 [==============================] - 0s 689us/step - loss: 0.2140\n",
      "Epoch 4/10\n",
      "63/63 [==============================] - 0s 615us/step - loss: 0.1192\n",
      "Epoch 5/10\n",
      "63/63 [==============================] - 0s 683us/step - loss: 0.0844\n",
      "Epoch 6/10\n",
      "63/63 [==============================] - 0s 919us/step - loss: 0.0673\n",
      "Epoch 7/10\n",
      "63/63 [==============================] - 0s 699us/step - loss: 0.0574\n",
      "Epoch 8/10\n",
      "63/63 [==============================] - 0s 928us/step - loss: 0.0512\n",
      "Epoch 9/10\n",
      "63/63 [==============================] - 0s 653us/step - loss: 0.0468\n",
      "Epoch 10/10\n",
      "63/63 [==============================] - 0s 996us/step - loss: 0.0435\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f7e13cb0c8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(units=25,activation='relu'),\n",
    "    Dense(units=15,activation='relu'),\n",
    "    Dense(units=4,activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "             optimizer=tf.keras.optimizers.Adam(0.001),)\n",
    "\n",
    "model.fit(X_train,y_train,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0af76a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 674us/step\n",
      "[[1.4677609e-03 1.4148162e-03 9.6415544e-01 3.2962032e-02]\n",
      " [9.8882282e-01 1.0765087e-02 3.0768575e-04 1.0433059e-04]]\n",
      "largest value 0.9999961 smallest value 8.694405e-11\n"
     ]
    }
   ],
   "source": [
    "p_nonpreferred = model.predict(X_train)\n",
    "print(p_nonpreferred [:2])\n",
    "print(\"largest value\", np.max(p_nonpreferred), \"smallest value\", np.min(p_nonpreferred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a0b6fa",
   "metadata": {},
   "source": [
    "The output provided is the probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b389cf0",
   "metadata": {},
   "source": [
    "## Model which is preffered having less numerical Rounoff Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab23a4d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "63/63 [==============================] - 0s 793us/step - loss: 0.8069\n",
      "Epoch 2/10\n",
      "63/63 [==============================] - 0s 725us/step - loss: 0.3665\n",
      "Epoch 3/10\n",
      "63/63 [==============================] - 0s 646us/step - loss: 0.1618\n",
      "Epoch 4/10\n",
      "63/63 [==============================] - 0s 770us/step - loss: 0.0918\n",
      "Epoch 5/10\n",
      "63/63 [==============================] - 0s 635us/step - loss: 0.0662\n",
      "Epoch 6/10\n",
      "63/63 [==============================] - 0s 658us/step - loss: 0.0538\n",
      "Epoch 7/10\n",
      "63/63 [==============================] - 0s 669us/step - loss: 0.0463\n",
      "Epoch 8/10\n",
      "63/63 [==============================] - 0s 725us/step - loss: 0.0409\n",
      "Epoch 9/10\n",
      "63/63 [==============================] - 0s 657us/step - loss: 0.0375\n",
      "Epoch 10/10\n",
      "63/63 [==============================] - 0s 678us/step - loss: 0.0345\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f7e29e9308>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preffered = Sequential([\n",
    "    Dense(units=25,activation='relu'),\n",
    "    Dense(units=15,activation='relu'),\n",
    "    Dense(units=4,activation='linear')\n",
    "])\n",
    "\n",
    "model_preffered.compile(\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                optimizer = tf.keras.optimizers.Adam(0.001)\n",
    "                       )\n",
    "\n",
    "model_preffered.fit(X_train,y_train,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a2cb78e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 739us/step\n",
      "two example output vectors:\n",
      " [[-2.1648939  -1.5291836   3.9892135  -0.23768035]\n",
      " [ 6.5366626   1.1982427  -3.97533    -3.7934895 ]]\n",
      "largest value 12.664385 smallest value -9.028359\n"
     ]
    }
   ],
   "source": [
    "p_preferred = model_preffered.predict(X_train)\n",
    "print(f\"two example output vectors:\\n {p_preferred[:2]}\")\n",
    "print(\"largest value\", np.max(p_preferred), \"smallest value\", np.min(p_preferred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de73154",
   "metadata": {},
   "source": [
    "**Note: The output predictions are not probabilities!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa739ac",
   "metadata": {},
   "source": [
    "If the problem only requires a selection, that is sufficient where the largest value index gives the predicted output. Use NumPy [argmax](https://numpy.org/doc/stable/reference/generated/numpy.argmax.html) to select it. If the problem requires a probability, a softmax is required:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c61c19e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two example output vectors:\n",
      " [[2.0815765e-03 3.9307699e-03 9.7968656e-01 1.4301133e-02]\n",
      " [9.9516022e-01 4.7802068e-03 2.7076510e-05 3.2476168e-05]]\n",
      "largest value 0.9999997 smallest value 3.7928033e-10\n"
     ]
    }
   ],
   "source": [
    "sm_preferred = tf.nn.softmax(p_preferred).numpy()\n",
    "print(f\"two example output vectors:\\n {sm_preferred[:2]}\")\n",
    "print(\"largest value\", np.max(sm_preferred), \"smallest value\", np.min(sm_preferred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41153915",
   "metadata": {},
   "source": [
    "To return an integer representing the predicted target, you want the index of the largest probability. This is accomplished with the Numpy [argmax](https://numpy.org/doc/stable/reference/generated/numpy.argmax.html) function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e40da36",
   "metadata": {},
   "source": [
    "This gives us the rquired probability of different classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a79041",
   "metadata": {},
   "source": [
    "To select the most likely category, the softmax is not required. One can find the index of the largest output using [np.argmax()](https://numpy.org/doc/stable/reference/generated/numpy.argmax.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1538b255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.1648939  -1.5291836   3.9892135  -0.23768035], category: 2\n",
      "[ 6.5366626  1.1982427 -3.97533   -3.7934895], category: 0\n",
      "[ 4.717441   1.3192291 -2.9539359 -3.1261587], category: 0\n",
      "[-2.1094606   5.076804   -0.98137516 -1.982822  ], category: 1\n",
      "[-0.7942974 -1.4857364  4.6711507 -2.1158438], category: 2\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print( f\"{p_preferred[i]}, category: {np.argmax(p_preferred[i])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f611e95",
   "metadata": {},
   "source": [
    "When we compare this with above model non preferred one then we see that there directly we get the probabilities but here as we are using from_logits=True due to which we get probability in 2 steps procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7764c192",
   "metadata": {},
   "source": [
    "largest numerical value index in p_preferred gives the category or checkup the probability sm_preferred the one with highest probability gives the category"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a4365b",
   "metadata": {},
   "source": [
    "## SparseCategorialCrossentropy or CategoricalCrossEntropy\n",
    "Tensorflow has two potential formats for target values and the selection of the loss defines which is expected.\n",
    "- SparseCategorialCrossentropy: expects the target to be an integer corresponding to the index. For example, if there are 10 potential target values, y would be between 0 and 9. \n",
    "- CategoricalCrossEntropy: Expects the target value of an example to be one-hot encoded where the value at the target index is 1 while the other N-1 entries are zero. An example with 10 potential target values, where the target is 2 would be [0,0,1,0,0,0,0,0,0,0]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63fa1c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
